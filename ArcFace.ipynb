{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4522eaa",
   "metadata": {},
   "source": [
    "# C&A ArcFace Competition\n",
    "\n",
    "Seunghun Paik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e1dd4",
   "metadata": {},
   "source": [
    "# Import Tools\n",
    "- model: backbone models\n",
    "- header: headers\n",
    "- data_process: dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from header import *\n",
    "from data_process import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device choice\n",
    "if torch.cuda.is_available():\n",
    "    # Use gpu(0)\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"Gpu #%d activated...\"%torch.cuda.current_device())\n",
    "    device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e3c39",
   "metadata": {},
   "source": [
    "# Hyperparameter Management\n",
    "Overall Hyperparameters, just like as `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image folder path\n",
    "img_dir = './faces_dataset/'\n",
    "idx_path = 'train.idx'\n",
    "rec_path = 'train.rec'\n",
    "\n",
    "# Dataset & Training Loop\n",
    "img_shape = (3,112,112)\n",
    "batch_size = 64\n",
    "epoch = 34\n",
    "\n",
    "# margins for arcface/cosface\n",
    "emb_size = 512\n",
    "scale = 64\n",
    "margin = 0.5\n",
    "\n",
    "# Optimizer\n",
    "lr_backbone = 0.05\n",
    "lr_header = 0.05\n",
    "weight_decay = 2e-4\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "\n",
    "# Scheduler\n",
    "gam_backbone = 0.93\n",
    "gam_header = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac297f5",
   "metadata": {},
   "source": [
    "# Get Dataset & DataLoader\n",
    "- Casia_WebFace is used\n",
    "- Dataset & DataLoader Implemented\n",
    "- Load data on cpu (RAM) / allocate to gpu at train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94df65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(img_dir, idx_path, rec_path)\n",
    "dataloader = DataLoader(train_dataset, batch_size, \n",
    "                        shuffle = True, drop_last = True)\n",
    "\n",
    "num_classes = train_dataset.num_classes\n",
    "img_shape = train_dataset.shape\n",
    "num_imgs = train_dataset.__len__()\n",
    "#Test; use 10% of the total dataset.\n",
    "#num_imgs =  50000\n",
    "print(\"# of classes : \", num_classes)\n",
    "print(\"Image shape : \", img_shape)\n",
    "print(\"# of images : \", num_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9487259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the input image\n",
    "import matplotlib.pyplot as plt\n",
    "img, label = train_dataset.__getitem__(239469)\n",
    "img_numpy = ((img+1.)/2.).numpy().transpose(1,2,0)\n",
    "plt.imshow(img_numpy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baff466",
   "metadata": {},
   "source": [
    "# Import Model and Allocate to Device\n",
    "- Resnet => 18,34,50,100 supported\n",
    "- header => plain, cosface, arcface, supported\n",
    "- adacos, partialfc, magface => Not Implemented Yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c69a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Backbone and Header\n",
    "num_backbone_layer = 50\n",
    "header_type = \"arcface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Backbone and Header\n",
    "backbone = get_resnet(num_backbone_layer, emb_size)\n",
    "header = get_header(header_type, emb_size=emb_size,\n",
    "                    num_classes=num_classes,\n",
    "                    scale=scale, margin=margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed parameters from RAM to GPU\n",
    "backbone = backbone.to(device)\n",
    "header = header.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d7d4",
   "metadata": {},
   "source": [
    "# Optimizer and LR scheduler\n",
    "SGD w/ Momentum\n",
    "\n",
    "- learning rate : 0.05\n",
    "- weight decay : 2e-4\n",
    "- momentum : 0.9 \n",
    "- batch_size = 64\n",
    "- Image: 112x112 => 512D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d450c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_type = 'sgd'\n",
    "\n",
    "if optim_type == \"adam\":\n",
    "    optim_backbone = torch.optim.Adam(backbone.parameters(), lr = lr_backbone,\n",
    "                                betas = [beta1,beta2], weight_decay = weight_decay)\n",
    "    optim_header = torch.optim.Adam(header.parameters(), lr=lr_header,\n",
    "                              betas = [beta1, beta2], weight_decay = weight_decay)\n",
    "    \n",
    "if optim_type == \"sgd\":\n",
    "    optim_backbone = torch.optim.SGD(backbone.parameters(), lr = lr_backbone,\n",
    "                                    momentum = 0.9, weight_decay = weight_decay)\n",
    "    optim_header = torch.optim.SGD(header.parameters(), lr= lr_header,\n",
    "                                  momentum = 0.9, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar LR schedule policy as original paper / Continuously changing LR\n",
    "# Header =>  LR shrinks faster\n",
    "\n",
    "sched_type = 'exp'\n",
    "\n",
    "if sched_type == 'exp':\n",
    "    sched_backbone = torch.optim.lr_scheduler.ExponentialLR(optim_backbone,\n",
    "                                                       gam_backbone)\n",
    "    sched_header = torch.optim.lr_scheduler.ExponentialLR(optim_header,\n",
    "                                                     gam_header)\n",
    "    \n",
    "if sched_type == 'step':\n",
    "    sched_backbone = torch.optim.lr_scheduler.MultiStepLR(optim_backbone,\n",
    "                                                         milestones = [10,17,23,27,31], gamma=0.35)\n",
    "    sched_header = torch.optim.lr_scheduler.MultiStepLR(optim_header,\n",
    "                                                       milestones = [10,15,20,25,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8af37e",
   "metadata": {},
   "source": [
    "# Train & Evaluation Code\n",
    "To measure the time consumed, module `time` is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from verification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22254ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lfw = load_bin(img_dir+\"/lfw.bin\", (112,112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Current Parameters\n",
    "\n",
    "def save_model_parameters(model, name):\n",
    "    dir_header = \"./params/\"\n",
    "    torch.save(model.state_dict(), dir_header+name+'_params.pth')\n",
    "    \n",
    "    \n",
    "def save_model(model, name):\n",
    "    dir_header = \"./params/\"\n",
    "    torch.save(model, dir_header+name+'_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, epoch, backbone, header, \n",
    "          optim_header, optim_backbone,\n",
    "         sched_backbone, sched_header, tag):\n",
    "    size = len(dataloader.dataset)\n",
    "    dir_prefix = \"/params/\"\n",
    "    dir_suffix = \".pth\"\n",
    "    acc_track = [0] * epoch\n",
    "    loss_track = [0] * epoch\n",
    "    \n",
    "    state = tag+\"_started.\"\n",
    "    logging('log.txt', state)\n",
    "    \n",
    "    for ech in range(epoch):\n",
    "        tic_ech = time.time()\n",
    "        tic_batch = time.time()\n",
    "        \n",
    "        cnt_ans = 0\n",
    "        \n",
    "        print(\"epoch {} begins\".format(ech+1))\n",
    "        print(\"Learning rate backbone: {}\".format(optim_backbone.param_groups[0]['lr']))\n",
    "        print(\"Learning rate header: {}\".format(optim_header.param_groups[0]['lr']))\n",
    "        \n",
    "        for idx,(x,y) in enumerate(dataloader):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Forward_pass\n",
    "            feature = backbone(x)\n",
    "            loss = header(feature,y)\n",
    "\n",
    "            # Backward_pass\n",
    "            optim_header.zero_grad()\n",
    "            optim_backbone.zero_grad()\n",
    "            loss.backward()\n",
    "            optim_header.step()\n",
    "            optim_backbone.step()\n",
    "            \n",
    "            # Logging for 200 steps\n",
    "            if idx % 200 == 0 and idx !=0:\n",
    "                toc_batch = time.time()\n",
    "                \n",
    "                loss, current = loss.item(), idx * batch_size\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{num_imgs:>5d}]\")\n",
    "                print(\"time consumed : \", toc_batch - tic_batch)\n",
    "\n",
    "                \n",
    "                tic_batch = time.time()\n",
    "                \n",
    "                state = \"Epoch#{}_Iter#{}_loss: {:.3f}\".format(ech+1, current,loss)\n",
    "                logging(\"log.txt\",state)\n",
    "            \n",
    "            if idx * batch_size > num_imgs:\n",
    "                break\n",
    "                \n",
    "        \n",
    "        toc_ech = time.time()\n",
    "        \n",
    "        # Logging for each epoch\n",
    "        print()\n",
    "        print(\"epoch %d done.\"%(ech+1))\n",
    "        print(\"time consumed : \", toc_ech-tic_ech)\n",
    "   \n",
    "        sched_backbone.step()\n",
    "        sched_header.step()\n",
    "        \n",
    "        acc1, std1, acc2, std2 ,xnorm, _ = test(dataset_lfw, \n",
    "                                   backbone, batch_size, device, nfolds=10)\n",
    "        \n",
    "        print(\"[Accuracy: {:.3f}+-{:3f}]\".format(acc2*100,std2*100))\n",
    "        print(\"[Xnorm: {:.3f}]\".format(xnorm))\n",
    "        print()\n",
    "        \n",
    "        state = \"Epoch#{} end, Accuracy: {:.3f}, Time Consumed: {:.3f}\".format(ech+1, acc2*100, toc_ech-tic_ech)\n",
    "        logging(\"log.txt\",state)\n",
    "        \n",
    "        if ech%5 ==0 and ech>0:\n",
    "            save_model(backbone, header_type + \"_\"+tag+ \"_backbone_%d\"%(ech+1))\n",
    "            save_model(header, header_type + \"_\"+tag+\"_header_%d\"%(ech+1))\n",
    "        acc_track[ech] = acc2\n",
    "        loss_track[ech] = loss\n",
    "        \n",
    "    return acc_track, loss_track\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8970f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import datetime\n",
    "\n",
    "def logging(name, state):\n",
    "    curr_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    f = open(name, 'a')\n",
    "    f.write(\"[{}] \".format(curr_time)+ state+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4d76b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tracking computed accuracy and loss\n",
    "acc_track, loss_track = train(dataloader, epoch, backbone, header, optim_header, optim_backbone,\n",
    "     sched_backbone, sched_header, tag=\"arc_res50_adam_0.05_step_do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Tools\n",
    "def viz_loss(loss_track, acc_track):\n",
    "    losses = [loss.item() for loss in loss_track]\n",
    "    acces = acc_track\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(losses)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(acces)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f27432",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_loss(loss_track, acc_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9949e6",
   "metadata": {},
   "source": [
    "# Visualization Tool\n",
    "Use MatPlotLib to Visualize the model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19774cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cac643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiazation Tools\n",
    "import random\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize(img1, img2):\n",
    "    # img: 1 X 3 X 112 X 112 / torch.Tonsor\n",
    "    # Feature extraction => Angular Distance Check\n",
    "    \n",
    "    img1 = img1.to(device)\n",
    "    img2 = img2.to(device)\n",
    "    backbone.eval()\n",
    "    feat1 = backbone(img1.unsqueeze(0))\n",
    "    feat2 = backbone(img2.unsqueeze(0))\n",
    "    \n",
    "    norm_feat1, norm_feat2 = F.normalize(feat1), F.normalize(feat2)\n",
    "    cos_value = torch.dot(norm_feat1.squeeze(0), norm_feat2.squeeze(0))\n",
    "\n",
    "    angular_dist = torch.acos(cos_value).item() * (180 / 3.14)\n",
    "    \n",
    "    img1_np = (img1.cpu().numpy().transpose(1,2,0) + 1.)/2\n",
    "    img2_np = (img2.cpu().numpy().transpose(1,2,0)+1.)/2\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img1_np)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img2_np)\n",
    "    plt.show()\n",
    "    print(\"Angular Distnace is : \", angular_dist)\n",
    "    print(\"Cosine value is : \", cos_value.item())\n",
    "    \n",
    "    backbone.train()\n",
    "\n",
    "    return \n",
    "\n",
    "# Get image from dataset and Visualize;\n",
    "r1, r2 = random.randint(0, num_imgs), random.randint(0, num_imgs)\n",
    "img1, img2 = train_dataset.__getitem__(r1), train_dataset.__getitem__(r2)\n",
    "visualize(img1[0], img2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650f0c9",
   "metadata": {},
   "source": [
    "# Save & Load Parameter\n",
    "Model parameters are saved at \"/params/\". Format is ***.pth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58aa81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Parameters\n",
    "\n",
    "def load_model_params(model, name):\n",
    "    dir_header = \"./params/\"\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load(dir_header+name+'_params.pth'))\n",
    "        return model\n",
    "        \n",
    "    except:\n",
    "        print(\"Invalid Loading, Quitting...\")\n",
    "        return\n",
    "\n",
    "def load_model(name):\n",
    "    dir_header = \"./params/\"\n",
    "    \n",
    "    try:\n",
    "        model = torch.load(dir_h eader + name _'_models.pth')\n",
    "        return model\n",
    "    \n",
    "    except:\n",
    "        print(\"Invalid Loading, Quitting...\")\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
